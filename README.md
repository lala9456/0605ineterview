# 0605ineterview
# 評測題目 
1. 數據處理
2. 模型訓練及選用問題，預測指定的symbol在90天後，是否有成長10%。

# 一、數據處理
請見EDA.ipynb檔案

# 二、模型訓練及選用問題
## 目標：預測指定的symbol在90天後，是否有成長10%。
## 1. 選用的模型及原因
### 資料特性
- 用分類模型(是否成長超過10%)或是時間序列模型來進行訓練
- 在整份資料中(成長超過10%)的資料比例只有約15%
- 總共736筆資料

### 模型選擇：
- **ARIMA**
- **Logistic Regression**
- **Random Forest**
- **Long Short-Term Memory(LSTM)**

### 模型選擇原因：
- **ARIMA** 適合時間序列的模型，可以捕捉具有季節性或是週期性的資料
- **Logistic Regression** 二元分配模型，解釋性強。
- **Random Forest** 處理多元變數較強的模型，也可以藉由此模型挑選變數。
- **Long Short-Term Memory(LSTM)** 深度學習模型中各層保有輸入順序適合時間數列的模型。

## ARIMA
- 直接預測1-90日後的股價
1. 檢查數列是否平穩
2. 不平穩則進行差分
3. 利用ACF以及PACF選擇模型的order
4. 以前段資料為訓練集，最後90天之資料為測試集預測股價
- 預測結果以及優缺點摘要
    - 優點：
    1. 可以藉由數學以及統計檢定的方式證明收盤價具有趨勢以及週期性
    - 缺點：
    1. 預測結果並未符合週期
    2. 只用一項變數進行模型建立，忽略掉其他影響股價的因素

## Logistic Regression
- 將90天後成功成長超過10%的資料做標註，並以此為目標作為預測
1. 進行變數篩選
2. 隨機切割訓練以及測試資料集
3. 以訓練集建立模型，並評估此模型在測試集的表現
- 預測結果以及優缺點摘要
    - 優點：
    1. 使用到更多變數，並且能解釋個變數對於股價可能之影響
    - 缺點：
    1. imbalance data造成accuracy高估的情況
    2. 忽略時間的因素

## Random Forest
前處理大致上與Logistic Regression相同
- 預測結果以及優缺點摘要
    - 優點：
    1. 較高的分類準確率
    2. Feature importances功能可以利用Entropy以及模型多棵決策樹等特性幫助我們篩選出重要的變數
    - 缺點：
    1. imbalance data造成accuracy高估的情況
    2. 忽略時間的因素

## Long Short-Term Memory(LSTM)
- 直接預測1-90日後的股價
- 預測結果以及優缺點摘要
    - 優點：
    1. 可以較精確且直接預測多期後的股價走勢且前期預測非常準確
    - 缺點：
    1. 我們的資料量不夠大，暫時無法確認是否有overfited的情況
    2. 訓練時間較長，計算資源需求，模型參數調校複雜。

## 小結
- 不同的模型有不同的特性，能從訓練不同的模型中取得不同的資訊
    - ARIMA：證明了我們的資料有週期以及季節性等時間因素之波動
    - Logistic Regression：提供了變數的解釋方法
    - Random Forest：提供一種變數選擇之方法
    - LSTM：綜合以上訓練並提供較為精確的股價預測模型

## 2. 從現有的數據集中提取關鍵影響欄位
### 目前已以下兩種方式來選擇變數
- 相關性分析：建立相關係數矩陣，選擇相關性較高的特徵。
- 特徵重要性：使用Random Forest訓練後，以Feature importances功能找出可能的變數。

## 3. 利用目前已有的數據集欄位，推論出更有效的新資料欄位
- 結合股市技術分析指標，參考常見的交易策略推測可能的新指標，舉例如下
    - 利用利用當日之最高價、最低價、開盤價、收盤價標繪製k線並標註每日k線型態
    - 標註當期的支撐以及壓力線，新增是否跌破或突破支撐壓力線
    - 標註是否跌破或突破均線
- [參考資料](https://www.thinkmarkets.com/tw/learn-to-trade/indicators-and-patterns/)